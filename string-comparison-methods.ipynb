{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating String Comparison Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say I have a large list of change ticket titles: \n",
    "\n",
    "```\n",
    "changes = [\n",
    "    \"CHNG559732: Recent deployment on foodatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022\",\n",
    "    \"CHNG494690: Recent deployment on legacycassandradbnodeserv for manifest ID legacycassandradbnodeserv-062723230148700108\",\n",
    "    \"CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462\",\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Let's also assume then that I have alerts that goes off. An example alert title may look like: \n",
    "```\n",
    "alert = \"Increase in FCIs on /api/v1/foo/status over the past 5 minutes\"\n",
    "```\n",
    "\n",
    "In this example, notice there is a relationship between \"/api/v1/foo/status\" in the alert and an application name \"foodatabasenodeserv\" is present in the first item of the change ticket list. Here \"foo\" establishes the relationship between the two. However, the change ticket list, the app names involved and the content of alerts will be constantly changing. \n",
    "\n",
    "How can I compare an alert against a large list of changes to find commonalities and relationships?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently OpenAI embeddings are far superior to any self-hosted options.\n",
    "\n",
    "Below are some quick attempts at using various ML methods to compare an alert against a set of change tickets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: fuzzywuzzy in /opt/conda/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Requirement already satisfied: python-Levenshtein in /opt/conda/lib/python3.10/site-packages (0.21.1)\n",
      "Requirement already satisfied: Levenshtein==0.21.1 in /opt/conda/lib/python3.10/site-packages (from python-Levenshtein) (0.21.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy fuzzywuzzy scikit-learn\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import Levenshtein\n",
    "import spacy\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "except OSError:\n",
    "    spacy.cli.download(\"en_core_web_lg\")\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert = \"Increase in FCIs on /api/v1/azure/status over the past 5 minutes\"\n",
    "alert2 = \"Success rate of paypaldatabasenodeserv has dropped below 99.999% over the past 5 minutes\"\n",
    "changes = [\n",
    "    \"CHNG559732: Recent deployment on azuredatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022\",\n",
    "    \"CHNG494690: Recent deployment on legacycassandradbnodeserv for manifest ID legacycassandradbnodeserv-062723230148700108\",\n",
    "    \"CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Compute Similarity Score using Spacy\n",
    "\n",
    "TBD:\n",
    "- Why is the distance of each the same; the changes are unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increase in FCIs on /api/v1/azure/status over the past 5 minutes <-> CHNG559732: Recent deployment on azuredatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022\n",
      "Similarity: 0.5555793900741783\n",
      "\n",
      "Increase in FCIs on /api/v1/azure/status over the past 5 minutes <-> CHNG494690: Recent deployment on legacycassandradbnodeserv for manifest ID legacycassandradbnodeserv-062723230148700108\n",
      "Similarity: 0.5555793900741783\n",
      "\n",
      "Increase in FCIs on /api/v1/azure/status over the past 5 minutes <-> CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462\n",
      "Similarity: 0.5555793900741783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity with each change string\n",
    "alert_doc = nlp(alert)\n",
    "for change in changes:\n",
    "    change_doc = nlp(change)\n",
    "    similarity = alert_doc.similarity(change_doc)\n",
    "    print(alert_doc, \"<->\", change_doc)\n",
    "    print(\"Similarity:\", similarity)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Extract Entity Relationships w/ Spacy & Fuzzywuzzy\n",
    "\n",
    "We can see here that the values extracted are low quality. This is likely do to the case that the items we're searching for are not common English terms, but moreso related to Linux and/or web service names. \n",
    "\n",
    "TBD:\n",
    "- Weirdness: Using a larger spacy model produces poorer quality matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities extracted from Increase in FCIs on /api/v1/azure/status over the past 5 minutes:\n",
      "['/api', 'the past 5 minutes']\n",
      "\n",
      "Entities extracted from CHNG559732: Recent deployment on azuredatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022:\n",
      "['CHNG559732']\n",
      "\n",
      "Entities extracted from CHNG494690: Recent deployment on legacycassandradbnodeserv for manifest ID legacycassandradbnodeserv-062723230148700108:\n",
      "[]\n",
      "\n",
      "Entities extracted from CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462:\n",
      "['CHNG336829', 'oldpostgresadapternodeweb-062723230148703462']\n",
      "\n",
      "\n",
      "Relationships found:\n",
      "Entity from Alert: the past 5 minutes\n",
      "Entity from Ticket: CHNG559732\n",
      "Change Ticket: CHNG559732: Recent deployment on azuredatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022\n",
      "\n",
      "Entity from Alert: the past 5 minutes\n",
      "Entity from Ticket: CHNG336829\n",
      "Change Ticket: CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462\n",
      "\n",
      "Entity from Alert: the past 5 minutes\n",
      "Entity from Ticket: oldpostgresadapternodeweb-062723230148703462\n",
      "Change Ticket: CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def extract_entities(text):\n",
    "    nlp = spacy.load(\"en_core_web_lg\") # CHANGE ME! (en_core_web_sm, en_core_web_md, en_core_web_lg)\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    print(f\"Entities extracted from {text}:\\n{entities}\\n\")\n",
    "    return entities\n",
    "\n",
    "def find_relationships(alert, change_tickets):\n",
    "    alert_entities = extract_entities(alert)\n",
    "    relationships = []\n",
    "\n",
    "    for ticket in change_tickets:\n",
    "        ticket_entities = extract_entities(ticket)\n",
    "\n",
    "        for alert_entity in alert_entities:\n",
    "            for ticket_entity in ticket_entities:\n",
    "                similarity = fuzz.ratio(alert_entity.lower(), ticket_entity.lower())\n",
    "                if similarity >= 10:  # Adjust the similarity threshold as needed\n",
    "                    relationships.append((alert_entity, ticket_entity, ticket))\n",
    "\n",
    "    return relationships\n",
    "\n",
    "def main():\n",
    "    relationships = find_relationships(alert, changes)\n",
    "\n",
    "    if relationships:\n",
    "        print(\"\\nRelationships found:\")\n",
    "        for alert_entity, ticket_entity, ticket in relationships:\n",
    "            print(f\"Entity from Alert: {alert_entity}\")\n",
    "            print(f\"Entity from Ticket: {ticket_entity}\")\n",
    "            print(f\"Change Ticket: {ticket}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"\\nNo relationships found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Using Spacy filters to identify tags\n",
    "\n",
    "Resources:\n",
    "- https://spacy.io/usage/rule-based-matching#entityruler\n",
    "- https://stackoverflow.com/questions/57667710/using-regex-for-phrase-pattern-in-entityruler\n",
    "\n",
    "TBD:\n",
    "- BUSINESS does not match when paypal is part of service name?\n",
    "- ENDPOINT also captures the timeframe (last 5 minutes)\n",
    "- TIMEFRAME is no longer captured after adding patterns (last 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    \"/v1/azure/status over the past 5 minutes\",\n",
      "    \"ENDPOINT\"\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [\n",
    "    {\n",
    "        \"label\": \"BUSINESS\",\n",
    "        \"id\": \"BUSINESS\",\n",
    "        \"pattern\": [{\n",
    "            \"LOWER\": \"paypal\"\n",
    "        }]\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"ENDPOINT\", \n",
    "        \"pattern\": [\n",
    "            {\n",
    "                \"ORTH\": \"/\"\n",
    "            }, \n",
    "            {\n",
    "                \"IS_ASCII\": True, \n",
    "                \"OP\": \"+\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"SERVICE\", \n",
    "        \"id\": \"SERVICE\",\n",
    "        \"pattern\": [{\n",
    "            \"LOWER\": {\"regex\": \"\\w+(serv|nodeserv|nodeweb)\"}\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(alert) # Swap between alert and alert2 to test\n",
    "output = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "print (json.dumps(output, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) TF-DIF\n",
    "\n",
    "Resources:\n",
    "- https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/\n",
    "- https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Similar Changes:\n",
      "\n",
      "Change: CHNG559732: Recent deployment on azuredatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022\n",
      "Similarity Score: 0.02813756547803127\n",
      "\n",
      "Change: CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462\n",
      "Similarity Score: 0.028137565478031264\n",
      "\n",
      "Change: CHNG494690: Recent deployment on legacycassandradbnodeserv for manifest ID legacycassandradbnodeserv-062723230148700108\n",
      "Similarity Score: 0.028137565478031264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Create a TF-IDF vectorizer instance\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer and transform the data\n",
    "tfidf_matrix = vectorizer.fit_transform([alert] + changes)\n",
    "\n",
    "# Get the TF-IDF vectors\n",
    "alert_tfidf = tfidf_matrix[0]\n",
    "change_tfidf = tfidf_matrix[1:]\n",
    "\n",
    "# Compare TF-IDF vectors\n",
    "similarities = cosine_similarity(alert_tfidf, change_tfidf)\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "# Find top 3 similar changes\n",
    "top_indices = np.argsort(similarities, axis=1)[0, ::-1][:3]\n",
    "top_changes = [changes[i] for i in top_indices]\n",
    "top_scores = [similarities[0, i] for i in top_indices]\n",
    "\n",
    "print(\"Top 3 Similar Changes:\\n\")\n",
    "for change, score in zip(top_changes, top_scores):\n",
    "    print(\"Change:\", change)\n",
    "    print(\"Similarity Score:\", score)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) KeyBERT / BERTopic\n",
    "\n",
    "Resources:\n",
    "- https://coder.social/MaartenGr/KeyBERT/issues/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Levenshtein Distance\n",
    "\n",
    "Determine how different two strings are by counting the minimum number of changes needed to turn one string into the other. These changes can be adding, removing, or replacing individual characters. Lower score == better match. \n",
    "\n",
    "Resources:\n",
    "- https://www.statology.org/levenshtein-distance-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket: CHNG559732: Recent deployment on azuredatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022, Distance: 88\n",
      "Ticket: CHNG494690: Recent deployment on legacycassandradbnodeserv for manifest ID legacycassandradbnodeserv-062723230148700108, Distance: 98\n",
      "Ticket: CHNG336829: Recent deployment on oldpostgresadapternodeweb for manifest ID oldpostgresadapternodeweb-062723230148703462, Distance: 98\n",
      "\n",
      "Change with Minimum Distance:\n",
      "CHNG559732: Recent deployment on azuredatabasenodeserv for manifest ID azuredatabasenodeserv-062723230148699022\n",
      "Distance: 88\n"
     ]
    }
   ],
   "source": [
    "min_distance = float('inf')  # Initialize with a large value\n",
    "min_change = None\n",
    "\n",
    "for change in changes:\n",
    "    distance = Levenshtein.distance(alert, change)\n",
    "    print(f\"Ticket: {change}, Distance: {distance}\")\n",
    "    if distance < min_distance:\n",
    "        min_distance = distance\n",
    "        min_change = change\n",
    "\n",
    "if min_change is not None:\n",
    "    print(\"\\nChange with Minimum Distance:\")\n",
    "    print(min_change)\n",
    "    print(\"Distance:\", min_distance)\n",
    "else:\n",
    "    print(\"\\nNo changes found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
