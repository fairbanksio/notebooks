{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client as Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below is a ChatGPT prompt I am currently using. Can you suggest optimizations or improvements to this prompt? You can return the optimized prompt only, no other details need to be provided.\n",
      "```\n",
      "\n",
      "Based on the content of the provided image, can you suggest a relevant filename? Your response should be in JSON format with the key. Do not reply with any extra information other than the filename in JSON format.\n",
      "\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_ENDPOINT = \"http://192.168.4.5:11434\"\n",
    "OLLAMA_MODEL = \"mixtral:8x7b-instruct-v0.1-q3_K_M\"\n",
    "SYSTEM_PROMPT = \"You are an assistant designed to help create optimal system prompts for the ChatGPT model. My goal is to generate system prompts that will elicit the most accurate and helpful responses from the ChatGPT model, based on the user's specific needs and intentions.\"\n",
    "\n",
    "INPUT_PROMPT = \"\"\"\n",
    "Based on the content of the provided image, can you suggest a relevant filename? Your response should be in JSON format with the key. Do not reply with any extra information other than the filename in JSON format.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = f\"\"\"\n",
    "Below is a ChatGPT prompt I am currently using. Can you suggest optimizations or improvements to this prompt? You can return the optimized prompt only, no other details need to be provided.\n",
    "```\n",
    "{INPUT_PROMPT}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Based on the content of the provided image, please suggest a relevant filename in JSON format with the key 'filename'. Only return the filename in the following format: '{\\\"filename\\\": «your_suggested_filename»}'.\""
     ]
    }
   ],
   "source": [
    "ollama = Ollama(host=OLLAMA_ENDPOINT)\n",
    "stream = ollama.chat(\n",
    "    model=OLLAMA_MODEL,\n",
    "    stream=True,\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': SYSTEM_PROMPT,\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': USER_PROMPT,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
